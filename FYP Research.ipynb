{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of Data\n",
    "\n",
    "1. Extracting the raw questions, options, answers from the .js file\n",
    "2. Splitting the data to use for research\n",
    "3. Creation of the test cases:\n",
    "    - Case 1: Wrong answer, wrong explanation\n",
    "    - Case 2: Wrong answer, right explanation\n",
    "    - Case 3: Right answer, wrong explanation\n",
    "    - Case 4: Right answer, right explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting the raw questions, options, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of questions: 240\n",
      "         Title                                           Question  \\\n",
      "0  Easy Arrays                                  What is an array?   \n",
      "1  Easy Arrays                How is memory allocated for arrays?   \n",
      "2  Easy Arrays       What does the Insert operation do in arrays?   \n",
      "3  Easy Arrays        How are Python lists different from arrays?   \n",
      "4  Easy Arrays  What is the purpose of initializing the size o...   \n",
      "\n",
      "                                             Options  \\\n",
      "0  [A collection of similar elements, A collectio...   \n",
      "1  [Memory is allocated randomly, Memory is alloc...   \n",
      "2  [Deletes an element, Searches for an element, ...   \n",
      "3  [Python lists do not store values, Python list...   \n",
      "4  [To allocate memory, To delete elements, To se...   \n",
      "\n",
      "                                        Answer  \n",
      "0             A collection of similar elements  \n",
      "1         Memory is allocated at the beginning  \n",
      "2                        Inserts a new element  \n",
      "3  Python lists can store different data types  \n",
      "4                           To allocate memory  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def clean_js_content(content):\n",
    "    # Remove 'const' declarations and combine arrays\n",
    "    content = content.replace('const', '')\n",
    "    \n",
    "    # Split the content into individual array declarations\n",
    "    arrays = ['easy_arrays', 'medium_arrays', 'hard_arrays', \n",
    "              'easy_stacksandqueues', 'medium_stacksandqueues', 'hard_stacksandqueues',\n",
    "              'easy_linkedlist', 'medium_linkedlist', 'hard_linkedlists',\n",
    "              'easy_recursion', 'medium_recursion', 'hard_recursion',\n",
    "              'easy_trees', 'medium_trees', 'hard_trees',\n",
    "              'easy_hashing', 'medium_hashing', 'hard_hashing',\n",
    "              'easy_heaps', 'medium_heaps', 'hard_heaps',\n",
    "              'easy_graphs', 'medium_graphs', 'hard_graphs']\n",
    "    \n",
    "    all_questions = []\n",
    "    \n",
    "    for array_name in arrays:\n",
    "        try:\n",
    "            # Find the start of the array\n",
    "            start_idx = content.find(array_name + ' = [')\n",
    "            if start_idx == -1:\n",
    "                continue\n",
    "                \n",
    "            # Find the end of the array\n",
    "            end_idx = content.find('\\n]', start_idx)\n",
    "            if end_idx == -1:\n",
    "                continue\n",
    "                \n",
    "            # Extract the array content\n",
    "            array_content = content[start_idx + len(array_name + ' = ['):end_idx + 1]\n",
    "            \n",
    "            # Convert the content to valid JSON format\n",
    "            array_content = '[' + array_content.strip()\n",
    "            array_content = array_content.replace('\\n', '')\n",
    "            array_content = array_content.replace('    ', '')\n",
    "            \n",
    "            # Add missing commas between objects\n",
    "            array_content = array_content.replace('}{', '},{')\n",
    "            \n",
    "            # Add missing brackets if needed\n",
    "            if not array_content.startswith('['):\n",
    "                array_content = '[' + array_content\n",
    "            if not array_content.endswith(']'):\n",
    "                array_content = array_content + ']'\n",
    "            \n",
    "            # Fix missing commas between objects\n",
    "            array_content = array_content.replace('\"}{\"', '\"},{\"')\n",
    "            \n",
    "            try:\n",
    "                questions = json.loads(array_content)\n",
    "                all_questions.extend(questions)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing {array_name}: {e}\")\n",
    "                continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {array_name}: {e}\")\n",
    "            continue\n",
    "    return all_questions\n",
    "\n",
    "# Read the JS file\n",
    "with open('./data/questions.js', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Combine all questions into one list\n",
    "combined_questions = clean_js_content(content)\n",
    "\n",
    "# Now create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Title': [q['title'] for q in combined_questions],\n",
    "    'Question': [q['question'] for q in combined_questions],\n",
    "    'Options': [q['options'] for q in combined_questions],\n",
    "    'Answer': [q['options'][q['ans']] for q in combined_questions]\n",
    "})\n",
    "\n",
    "print(f\"Total number of questions: {len(df)}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"questions.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Title     240 non-null    object\n",
      " 1   Question  240 non-null    object\n",
      " 2   Options   240 non-null    object\n",
      " 3   Answer    240 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting the data to use for research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Easy Arrays                 1\n",
       "Easy Graphs                 1\n",
       "Medium Stacks and Queues    1\n",
       "Medium Recursion            1\n",
       "Medium Linked Lists         1\n",
       "Medium Heaps                1\n",
       "Medium Hashing              1\n",
       "Medium Graphs               1\n",
       "Medium Arrays               1\n",
       "Hard Trees                  1\n",
       "Hard Stacks and Queues      1\n",
       "Hard Recursion              1\n",
       "Hard Linked Lists           1\n",
       "Hard Heaps                  1\n",
       "Hard Hashing                1\n",
       "Hard Graphs                 1\n",
       "Hard Arrays                 1\n",
       "Easy Trees                  1\n",
       "Easy Stacks and Queues      1\n",
       "Easy Recursion              1\n",
       "Easy Linked Lists           1\n",
       "Easy Heaps                  1\n",
       "Easy Hashing                1\n",
       "Medium Trees                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting first 5 rows of each Title for testing\n",
    "\n",
    "first_per_title = df.groupby('Title').head(1)\n",
    "\n",
    "# Sort by Title to keep it organized\n",
    "first_per_title = first_per_title.sort_values('Title')\n",
    "\n",
    "# Reset the index\n",
    "first_per_title = first_per_title.reset_index(drop=True)\n",
    "\n",
    "first_per_title['Title'].value_counts()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Question</th>\n",
       "      <th>Options</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Easy Arrays</td>\n",
       "      <td>What is an array?</td>\n",
       "      <td>[A collection of similar elements, A collectio...</td>\n",
       "      <td>A collection of similar elements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy Graphs</td>\n",
       "      <td>What is a minimum spanning tree?</td>\n",
       "      <td>[A tree with the minimum number of edges from ...</td>\n",
       "      <td>A tree that minimizes the total weight of edge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easy Hashing</td>\n",
       "      <td>What is the primary purpose of using hashing i...</td>\n",
       "      <td>[To sort data efficiently, To store data in a ...</td>\n",
       "      <td>To quickly retrieve data based on a key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy Heaps</td>\n",
       "      <td>What data structure are heaps almost always im...</td>\n",
       "      <td>[Linked lists, Arrays, Hash tables, Stacks]</td>\n",
       "      <td>Arrays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easy Linked Lists</td>\n",
       "      <td>What is the main advantage of using a linked l...</td>\n",
       "      <td>[Constant time access to elements, Contiguous ...</td>\n",
       "      <td>Dynamic size</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title                                           Question  \\\n",
       "0        Easy Arrays                                  What is an array?   \n",
       "1        Easy Graphs                   What is a minimum spanning tree?   \n",
       "2       Easy Hashing  What is the primary purpose of using hashing i...   \n",
       "3         Easy Heaps  What data structure are heaps almost always im...   \n",
       "4  Easy Linked Lists  What is the main advantage of using a linked l...   \n",
       "\n",
       "                                             Options  \\\n",
       "0  [A collection of similar elements, A collectio...   \n",
       "1  [A tree with the minimum number of edges from ...   \n",
       "2  [To sort data efficiently, To store data in a ...   \n",
       "3        [Linked lists, Arrays, Hash tables, Stacks]   \n",
       "4  [Constant time access to elements, Contiguous ...   \n",
       "\n",
       "                                              Answer  \n",
       "0                   A collection of similar elements  \n",
       "1  A tree that minimizes the total weight of edge...  \n",
       "2            To quickly retrieve data based on a key  \n",
       "3                                             Arrays  \n",
       "4                                       Dynamic size  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_per_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creation of the test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def generate_explanations(df, retriever, model):\n",
    "    \"\"\"\n",
    "    Generate explanations for a DataFrame of questions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with columns 'Question', 'Options', 'Answer'\n",
    "    retriever : Retriever\n",
    "        LangChain retriever for context\n",
    "    model : ChatModel\n",
    "        Language model for generating explanations\n",
    "    prompt_template : str\n",
    "        Prompt template for explanation generation\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with added 'Explanation' column\n",
    "    \"\"\"\n",
    "    template = \"\"\"\n",
    "    Answer the question based only on the following context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Create the chain\n",
    "    # chain = (\n",
    "    #     {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    #     | prompt\n",
    "    #     | model\n",
    "    #     | StrOutputParser()\n",
    "    # )\n",
    "\n",
    "    chain = (\n",
    "        RunnablePassthrough()\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # Function to generate explanation for a single row\n",
    "    def generate_explanation(row):\n",
    "        text = f\"\"\"\n",
    "        Given the question and the options:\n",
    "        {row['Question']}\n",
    "        {row['Options']}\n",
    "\n",
    "        The correct answer is {row['Answer']}.\n",
    "\n",
    "        Please do the following:\n",
    "        1. Give an accurate explanation for the correct answer\n",
    "        2. Choose one of the wrong answers\n",
    "        3. Pretend you are a misguided student, create a plausible wrong explanation for the chosen wrong answer\n",
    "\n",
    "        ## Sample output format in JSON respectively:\n",
    "        \"Correct explanation\": \"XXX\", \"Wrong chosen answer\": \"YYY\", \"Wrong explanation\": \"ZZZ\"\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            explanation = chain.invoke(text)\n",
    "            return explanation\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating explanation: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Apply the explanation generation to each row\n",
    "    tqdm.pandas()\n",
    "    df['Explanation'] = df.apply(generate_explanation, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Question</th>\n",
       "      <th>Options</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Easy Arrays</td>\n",
       "      <td>What is an array?</td>\n",
       "      <td>[A collection of similar elements, A collectio...</td>\n",
       "      <td>A collection of similar elements</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"An array is a dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy Graphs</td>\n",
       "      <td>What is a minimum spanning tree?</td>\n",
       "      <td>[A tree with the minimum number of edges from ...</td>\n",
       "      <td>A tree that minimizes the total weight of edge...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"A minimum spannin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easy Hashing</td>\n",
       "      <td>What is the primary purpose of using hashing i...</td>\n",
       "      <td>[To sort data efficiently, To store data in a ...</td>\n",
       "      <td>To quickly retrieve data based on a key</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Hashing is used i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy Heaps</td>\n",
       "      <td>What data structure are heaps almost always im...</td>\n",
       "      <td>[Linked lists, Arrays, Hash tables, Stacks]</td>\n",
       "      <td>Arrays</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Heaps are almost ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easy Linked Lists</td>\n",
       "      <td>What is the main advantage of using a linked l...</td>\n",
       "      <td>[Constant time access to elements, Contiguous ...</td>\n",
       "      <td>Dynamic size</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"The main advantag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Easy Recursion</td>\n",
       "      <td>What is a characteristic of recursive routines?</td>\n",
       "      <td>[They call themselves., Each call performs its...</td>\n",
       "      <td>They call themselves.</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"A characteristic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Easy Stacks and Queues</td>\n",
       "      <td>What data structure follows the Last In First ...</td>\n",
       "      <td>[Queue, Stack, Linked List, Array]</td>\n",
       "      <td>Stack</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"A Stack is a data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Easy Trees</td>\n",
       "      <td>In a binary tree, what is the maximum number o...</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"In a binary tree,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hard Arrays</td>\n",
       "      <td>Explain the difference between an unordered ar...</td>\n",
       "      <td>[Unordered arrays have faster search operation...</td>\n",
       "      <td>Ordered arrays store elements in ascending or ...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Ordered arrays st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hard Graphs</td>\n",
       "      <td>Explain the difference between a strong compon...</td>\n",
       "      <td>[A strong component has all vertices connected...</td>\n",
       "      <td>A strong component can be reached from any oth...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"In a directed gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hard Hashing</td>\n",
       "      <td>Explain the concept of a perfect hash function...</td>\n",
       "      <td>[A perfect hash function maps all keys to uniq...</td>\n",
       "      <td>A perfect hash function maps all keys to uniqu...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"A perfect hash fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hard Heaps</td>\n",
       "      <td>What is the time complexity of inserting N ite...</td>\n",
       "      <td>[O(N), O(log N), O(N log N), O(N^2)]</td>\n",
       "      <td>O(N log N)</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"The time complexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard Linked Lists</td>\n",
       "      <td>How does the time complexity of searching for ...</td>\n",
       "      <td>[Arrays have O(1) complexity, while linked lis...</td>\n",
       "      <td>Arrays have O(1) complexity, while linked list...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Arrays have O(1) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hard Recursion</td>\n",
       "      <td>What is the significance of memoization in rec...</td>\n",
       "      <td>[It ensures that the recursion depth is limite...</td>\n",
       "      <td>It stores intermediate results to avoid redund...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Memoization is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hard Stacks and Queues</td>\n",
       "      <td>In the context of a disaster scenario with lim...</td>\n",
       "      <td>[Allows for random access of patients, Enables...</td>\n",
       "      <td>Prioritizes patients based on severity</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"In a disaster sce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hard Trees</td>\n",
       "      <td>Explain the concept of trinode restructuring i...</td>\n",
       "      <td>[Trinode restructuring involves restructuring ...</td>\n",
       "      <td>Trinode restructuring involves restructuring t...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Trinode restructu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Medium Arrays</td>\n",
       "      <td>What is the time complexity of inserting an el...</td>\n",
       "      <td>[O(0), O(log N), O(N), O(N^2)]</td>\n",
       "      <td>O(0)</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"The correct answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Medium Graphs</td>\n",
       "      <td>In a directed graph, what is the term used to ...</td>\n",
       "      <td>[Cycle, Loop, Circuit, Traversal]</td>\n",
       "      <td>Cycle</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"In a directed gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Medium Hashing</td>\n",
       "      <td>What is the difference between linear probing ...</td>\n",
       "      <td>[Linear probing uses a fixed step size for pro...</td>\n",
       "      <td>Linear probing uses a fixed step size for prob...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"In hashing, linea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Medium Heaps</td>\n",
       "      <td>What is the time complexity of finding the K h...</td>\n",
       "      <td>[O(N + K^2), O(N × K), O(N + K × log N), O(N l...</td>\n",
       "      <td>O(N + K × log N)</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"To find the K hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Medium Linked Lists</td>\n",
       "      <td>What is the difference between a singly linked...</td>\n",
       "      <td>[Singly linked lists allow traversal in one di...</td>\n",
       "      <td>Singly linked lists allow traversal in one dir...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"A singly linked l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Medium Recursion</td>\n",
       "      <td>In recursion, what is the significance of the ...</td>\n",
       "      <td>[It stores local variables for each recursive ...</td>\n",
       "      <td>It manages the order of function calls</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"In recursion, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Medium Stacks and Queues</td>\n",
       "      <td>When folding rags to be used in cleaning, whic...</td>\n",
       "      <td>[Queue, Stack, Linked List, Priority Queue]</td>\n",
       "      <td>Stack</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"A stack is a data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Medium Trees</td>\n",
       "      <td>What is the time complexity for searching in a...</td>\n",
       "      <td>[O(1), O(log N), O(N), O(N^2)]</td>\n",
       "      <td>O(log N)</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"In a balanced bin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  \\\n",
       "0                Easy Arrays   \n",
       "1                Easy Graphs   \n",
       "2               Easy Hashing   \n",
       "3                 Easy Heaps   \n",
       "4          Easy Linked Lists   \n",
       "5             Easy Recursion   \n",
       "6     Easy Stacks and Queues   \n",
       "7                 Easy Trees   \n",
       "8                Hard Arrays   \n",
       "9                Hard Graphs   \n",
       "10              Hard Hashing   \n",
       "11                Hard Heaps   \n",
       "12         Hard Linked Lists   \n",
       "13            Hard Recursion   \n",
       "14    Hard Stacks and Queues   \n",
       "15                Hard Trees   \n",
       "16             Medium Arrays   \n",
       "17             Medium Graphs   \n",
       "18            Medium Hashing   \n",
       "19              Medium Heaps   \n",
       "20       Medium Linked Lists   \n",
       "21          Medium Recursion   \n",
       "22  Medium Stacks and Queues   \n",
       "23              Medium Trees   \n",
       "\n",
       "                                             Question  \\\n",
       "0                                   What is an array?   \n",
       "1                    What is a minimum spanning tree?   \n",
       "2   What is the primary purpose of using hashing i...   \n",
       "3   What data structure are heaps almost always im...   \n",
       "4   What is the main advantage of using a linked l...   \n",
       "5     What is a characteristic of recursive routines?   \n",
       "6   What data structure follows the Last In First ...   \n",
       "7   In a binary tree, what is the maximum number o...   \n",
       "8   Explain the difference between an unordered ar...   \n",
       "9   Explain the difference between a strong compon...   \n",
       "10  Explain the concept of a perfect hash function...   \n",
       "11  What is the time complexity of inserting N ite...   \n",
       "12  How does the time complexity of searching for ...   \n",
       "13  What is the significance of memoization in rec...   \n",
       "14  In the context of a disaster scenario with lim...   \n",
       "15  Explain the concept of trinode restructuring i...   \n",
       "16  What is the time complexity of inserting an el...   \n",
       "17  In a directed graph, what is the term used to ...   \n",
       "18  What is the difference between linear probing ...   \n",
       "19  What is the time complexity of finding the K h...   \n",
       "20  What is the difference between a singly linked...   \n",
       "21  In recursion, what is the significance of the ...   \n",
       "22  When folding rags to be used in cleaning, whic...   \n",
       "23  What is the time complexity for searching in a...   \n",
       "\n",
       "                                              Options  \\\n",
       "0   [A collection of similar elements, A collectio...   \n",
       "1   [A tree with the minimum number of edges from ...   \n",
       "2   [To sort data efficiently, To store data in a ...   \n",
       "3         [Linked lists, Arrays, Hash tables, Stacks]   \n",
       "4   [Constant time access to elements, Contiguous ...   \n",
       "5   [They call themselves., Each call performs its...   \n",
       "6                  [Queue, Stack, Linked List, Array]   \n",
       "7                                        [0, 1, 2, 3]   \n",
       "8   [Unordered arrays have faster search operation...   \n",
       "9   [A strong component has all vertices connected...   \n",
       "10  [A perfect hash function maps all keys to uniq...   \n",
       "11               [O(N), O(log N), O(N log N), O(N^2)]   \n",
       "12  [Arrays have O(1) complexity, while linked lis...   \n",
       "13  [It ensures that the recursion depth is limite...   \n",
       "14  [Allows for random access of patients, Enables...   \n",
       "15  [Trinode restructuring involves restructuring ...   \n",
       "16                     [O(0), O(log N), O(N), O(N^2)]   \n",
       "17                  [Cycle, Loop, Circuit, Traversal]   \n",
       "18  [Linear probing uses a fixed step size for pro...   \n",
       "19  [O(N + K^2), O(N × K), O(N + K × log N), O(N l...   \n",
       "20  [Singly linked lists allow traversal in one di...   \n",
       "21  [It stores local variables for each recursive ...   \n",
       "22        [Queue, Stack, Linked List, Priority Queue]   \n",
       "23                     [O(1), O(log N), O(N), O(N^2)]   \n",
       "\n",
       "                                               Answer  \\\n",
       "0                    A collection of similar elements   \n",
       "1   A tree that minimizes the total weight of edge...   \n",
       "2             To quickly retrieve data based on a key   \n",
       "3                                              Arrays   \n",
       "4                                        Dynamic size   \n",
       "5                               They call themselves.   \n",
       "6                                               Stack   \n",
       "7                                                   2   \n",
       "8   Ordered arrays store elements in ascending or ...   \n",
       "9   A strong component can be reached from any oth...   \n",
       "10  A perfect hash function maps all keys to uniqu...   \n",
       "11                                         O(N log N)   \n",
       "12  Arrays have O(1) complexity, while linked list...   \n",
       "13  It stores intermediate results to avoid redund...   \n",
       "14             Prioritizes patients based on severity   \n",
       "15  Trinode restructuring involves restructuring t...   \n",
       "16                                               O(0)   \n",
       "17                                              Cycle   \n",
       "18  Linear probing uses a fixed step size for prob...   \n",
       "19                                   O(N + K × log N)   \n",
       "20  Singly linked lists allow traversal in one dir...   \n",
       "21             It manages the order of function calls   \n",
       "22                                              Stack   \n",
       "23                                           O(log N)   \n",
       "\n",
       "                                          Explanation  \n",
       "0   {\\n  \"Correct explanation\": \"An array is a dat...  \n",
       "1   {\\n  \"Correct explanation\": \"A minimum spannin...  \n",
       "2   {\\n  \"Correct explanation\": \"Hashing is used i...  \n",
       "3   {\\n  \"Correct explanation\": \"Heaps are almost ...  \n",
       "4   {\\n  \"Correct explanation\": \"The main advantag...  \n",
       "5   {\\n  \"Correct explanation\": \"A characteristic ...  \n",
       "6   {\\n  \"Correct explanation\": \"A Stack is a data...  \n",
       "7   {\\n  \"Correct explanation\": \"In a binary tree,...  \n",
       "8   {\\n  \"Correct explanation\": \"Ordered arrays st...  \n",
       "9   {\\n  \"Correct explanation\": \"In a directed gra...  \n",
       "10  {\\n  \"Correct explanation\": \"A perfect hash fu...  \n",
       "11  {\\n  \"Correct explanation\": \"The time complexi...  \n",
       "12  {\\n  \"Correct explanation\": \"Arrays have O(1) ...  \n",
       "13  {\\n  \"Correct explanation\": \"Memoization is a ...  \n",
       "14  {\\n  \"Correct explanation\": \"In a disaster sce...  \n",
       "15  {\\n  \"Correct explanation\": \"Trinode restructu...  \n",
       "16  {\\n  \"Correct explanation\": \"The correct answe...  \n",
       "17  {\\n  \"Correct explanation\": \"In a directed gra...  \n",
       "18  {\\n  \"Correct explanation\": \"In hashing, linea...  \n",
       "19  {\\n  \"Correct explanation\": \"To find the K hig...  \n",
       "20  {\\n  \"Correct explanation\": \"A singly linked l...  \n",
       "21  {\\n  \"Correct explanation\": \"In recursion, the...  \n",
       "22  {\\n  \"Correct explanation\": \"A stack is a data...  \n",
       "23  {\\n  \"Correct explanation\": \"In a balanced bin...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    deployment_name=os.environ['AZURE_OPENAI_DEPLOYMENT_NAME'],\n",
    "    model_name=os.environ['AZURE_OPENAI_MODEL_NAME'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_API_KEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])\n",
    "docsearch = FAISS.load_local(folder_path=\"./embed\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = docsearch.as_retriever()\n",
    "\n",
    "generate_explanations(first_per_title, retriever, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Title        24 non-null     object\n",
      " 1   Question     24 non-null     object\n",
      " 2   Options      24 non-null     object\n",
      " 3   Answer       24 non-null     object\n",
      " 4   Explanation  24 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "first_per_title.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Question</th>\n",
       "      <th>Options</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Correct Explanation</th>\n",
       "      <th>Wrong Answer</th>\n",
       "      <th>Wrong Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Easy Arrays</td>\n",
       "      <td>What is an array?</td>\n",
       "      <td>[A collection of similar elements, A collectio...</td>\n",
       "      <td>A collection of similar elements</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"An array is a dat...</td>\n",
       "      <td>An array is a data structure that can hold mul...</td>\n",
       "      <td>A collection of different elements</td>\n",
       "      <td>An array is a versatile data structure that ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy Graphs</td>\n",
       "      <td>What is a minimum spanning tree?</td>\n",
       "      <td>[A tree with the minimum number of edges from ...</td>\n",
       "      <td>A tree that minimizes the total weight of edge...</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"A minimum spannin...</td>\n",
       "      <td>A minimum spanning tree (MST) is a subset of t...</td>\n",
       "      <td>A tree that spans all the vertices using the l...</td>\n",
       "      <td>A minimum spanning tree is a tree that spans a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easy Hashing</td>\n",
       "      <td>What is the primary purpose of using hashing i...</td>\n",
       "      <td>[To sort data efficiently, To store data in a ...</td>\n",
       "      <td>To quickly retrieve data based on a key</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Hashing is used i...</td>\n",
       "      <td>Hashing is used in data structures to quickly ...</td>\n",
       "      <td>To sort data efficiently</td>\n",
       "      <td>Hashing is used to sort data efficiently becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy Heaps</td>\n",
       "      <td>What data structure are heaps almost always im...</td>\n",
       "      <td>[Linked lists, Arrays, Hash tables, Stacks]</td>\n",
       "      <td>Arrays</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"Heaps are almost ...</td>\n",
       "      <td>Heaps are almost always implemented as arrays ...</td>\n",
       "      <td>Linked lists</td>\n",
       "      <td>Heaps are implemented as linked lists because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easy Linked Lists</td>\n",
       "      <td>What is the main advantage of using a linked l...</td>\n",
       "      <td>[Constant time access to elements, Contiguous ...</td>\n",
       "      <td>Dynamic size</td>\n",
       "      <td>{\\n  \"Correct explanation\": \"The main advantag...</td>\n",
       "      <td>The main advantage of using a linked list over...</td>\n",
       "      <td>Constant time access to elements</td>\n",
       "      <td>Linked lists provide constant time access to e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title                                           Question  \\\n",
       "0        Easy Arrays                                  What is an array?   \n",
       "1        Easy Graphs                   What is a minimum spanning tree?   \n",
       "2       Easy Hashing  What is the primary purpose of using hashing i...   \n",
       "3         Easy Heaps  What data structure are heaps almost always im...   \n",
       "4  Easy Linked Lists  What is the main advantage of using a linked l...   \n",
       "\n",
       "                                             Options  \\\n",
       "0  [A collection of similar elements, A collectio...   \n",
       "1  [A tree with the minimum number of edges from ...   \n",
       "2  [To sort data efficiently, To store data in a ...   \n",
       "3        [Linked lists, Arrays, Hash tables, Stacks]   \n",
       "4  [Constant time access to elements, Contiguous ...   \n",
       "\n",
       "                                              Answer  \\\n",
       "0                   A collection of similar elements   \n",
       "1  A tree that minimizes the total weight of edge...   \n",
       "2            To quickly retrieve data based on a key   \n",
       "3                                             Arrays   \n",
       "4                                       Dynamic size   \n",
       "\n",
       "                                         Explanation  \\\n",
       "0  {\\n  \"Correct explanation\": \"An array is a dat...   \n",
       "1  {\\n  \"Correct explanation\": \"A minimum spannin...   \n",
       "2  {\\n  \"Correct explanation\": \"Hashing is used i...   \n",
       "3  {\\n  \"Correct explanation\": \"Heaps are almost ...   \n",
       "4  {\\n  \"Correct explanation\": \"The main advantag...   \n",
       "\n",
       "                                 Correct Explanation  \\\n",
       "0  An array is a data structure that can hold mul...   \n",
       "1  A minimum spanning tree (MST) is a subset of t...   \n",
       "2  Hashing is used in data structures to quickly ...   \n",
       "3  Heaps are almost always implemented as arrays ...   \n",
       "4  The main advantage of using a linked list over...   \n",
       "\n",
       "                                        Wrong Answer  \\\n",
       "0                 A collection of different elements   \n",
       "1  A tree that spans all the vertices using the l...   \n",
       "2                           To sort data efficiently   \n",
       "3                                       Linked lists   \n",
       "4                   Constant time access to elements   \n",
       "\n",
       "                                   Wrong Explanation  \n",
       "0  An array is a versatile data structure that ca...  \n",
       "1  A minimum spanning tree is a tree that spans a...  \n",
       "2  Hashing is used to sort data efficiently becau...  \n",
       "3  Heaps are implemented as linked lists because ...  \n",
       "4  Linked lists provide constant time access to e...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def parse_explanation(explanation_str):\n",
    "    try:\n",
    "        # Extract Wrong explanation\n",
    "        correct_explanation_match = re.search(r'\"Correct explanation\":\\s*\"(.*?)\"', explanation_str, re.DOTALL)\n",
    "        correct_explanation = correct_explanation_match.group(1) if correct_explanation_match else ''\n",
    "        \n",
    "        # Extract Right explanation\n",
    "        wrong_answer_match = re.search(r'\"Wrong chosen answer\":\\s*\"(.*?)\"', explanation_str, re.DOTALL)\n",
    "        wrong_answer = wrong_answer_match.group(1) if wrong_answer_match else ''\n",
    "\n",
    "        wrong_explanation_match = re.search(r'\"Wrong explanation\":\\s*\"(.*?)\"', explanation_str, re.DOTALL)\n",
    "        wrong_explanation = wrong_explanation_match.group(1) if wrong_explanation_match else ''\n",
    "        \n",
    "        return pd.Series({\n",
    "            'Correct Explanation': correct_explanation,\n",
    "            'Wrong Answer': wrong_answer,\n",
    "            'Wrong Explanation': wrong_explanation\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing explanation: {e}\")\n",
    "        return pd.Series({\n",
    "            'Correct Explanation': '',\n",
    "            'Wrong Answer': '',\n",
    "            'Wrong Explanation': ''\n",
    "        })\n",
    "\n",
    "# Apply the parsing to your DataFrame\n",
    "first_per_title[['Correct Explanation', 'Wrong Answer', 'Wrong Explanation']] = first_per_title['Explanation'].apply(parse_explanation)\n",
    "first_per_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating test cases where each question can be split into 4 different scenarios\n",
    "- Case 1: Wrong answer, wrong explanation\n",
    "- Case 2: Wrong answer, right explanation\n",
    "- Case 3: Right answer, wrong explanation\n",
    "- Case 4: Right answer, right explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_row(row):\n",
    "    return [\n",
    "        # Wrong answer, wrong explanation\n",
    "        {'Title': row['Title'],\n",
    "         'Question': f\"\"\"\n",
    "        Given the question and the options:\n",
    "        {row['Question']}\n",
    "        {row['Options']}\n",
    "        The correct answer is {row['Answer']}\n",
    "\n",
    "        I chose the wrong answer {row['Wrong Answer']} as I think that {row['Wrong Explanation']}.\n",
    "\n",
    "        Please correct any conceptual misunderstanding I have based on my explanation and explain to me why my answer is wrong.\n",
    "        ## Sample format:\n",
    "        Your answer is wrong. Your understanding is wrong as...\n",
    "        \"\"\"},\n",
    "\n",
    "        # Wrong answer, correct explanation\n",
    "        {'Title': row['Title'],\n",
    "         'Question': f\"\"\"\n",
    "        Given the question and the options:\n",
    "        {row['Question']}\n",
    "        {row['Options']}\n",
    "        The correct answer is {row['Answer']}\n",
    "\n",
    "        I chose the wrong answer {row['Wrong Answer']} as I think that {row['Correct Explanation']}.\n",
    "\n",
    "        Please correct any conceptual misunderstanding I have based on my explanation and explain to me why my answer is wrong.\n",
    "        ## Sample format:\n",
    "        Your answer is wrong. Your understanding is wrong as...\n",
    "        \"\"\"},\n",
    "\n",
    "        # Correct answer, wrong explanation\n",
    "        {'Title': row['Title'],\n",
    "         'Question': f\"\"\"\n",
    "        Given the question and the options:\n",
    "        {row['Question']}\n",
    "        {row['Options']}\n",
    "        The correct answer is {row['Answer']}\n",
    "\n",
    "        I chose the correct answer {row['Answer']} as I think that {row['Wrong Explanation']}.\n",
    "\n",
    "        Please correct any conceptual misunderstanding I have based on my explanation.\n",
    "        ## Sample format:\n",
    "        Your answer is correct. Your understanding is partially correct as...\n",
    "        \"\"\"},\n",
    "\n",
    "        # Correct answer, correct explanation\n",
    "        {'Title': row['Title'],\n",
    "         'Question': f\"\"\"\n",
    "        Given the question and the options:\n",
    "        {row['Question']}\n",
    "        {row['Options']}\n",
    "        The correct answer is {row['Answer']}\n",
    "\n",
    "        I chose the correct answer {row['Answer']} as I think that {row['Correct Explanation']}.\n",
    "\n",
    "        Please correct any conceptual misunderstanding I have based on my explanation.\n",
    "        ## Sample format:\n",
    "        Your answer is correct. Your understanding is partially correct as...\n",
    "        \"\"\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Easy Arrays</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy Arrays</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easy Arrays</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy Arrays</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easy Graphs</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Medium Stacks and Queues</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Medium Trees</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Medium Trees</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Medium Trees</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Medium Trees</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  \\\n",
       "0                Easy Arrays   \n",
       "1                Easy Arrays   \n",
       "2                Easy Arrays   \n",
       "3                Easy Arrays   \n",
       "4                Easy Graphs   \n",
       "..                       ...   \n",
       "91  Medium Stacks and Queues   \n",
       "92              Medium Trees   \n",
       "93              Medium Trees   \n",
       "94              Medium Trees   \n",
       "95              Medium Trees   \n",
       "\n",
       "                                             Question  \n",
       "0   \\n        Given the question and the options:\\...  \n",
       "1   \\n        Given the question and the options:\\...  \n",
       "2   \\n        Given the question and the options:\\...  \n",
       "3   \\n        Given the question and the options:\\...  \n",
       "4   \\n        Given the question and the options:\\...  \n",
       "..                                                ...  \n",
       "91  \\n        Given the question and the options:\\...  \n",
       "92  \\n        Given the question and the options:\\...  \n",
       "93  \\n        Given the question and the options:\\...  \n",
       "94  \\n        Given the question and the options:\\...  \n",
       "95  \\n        Given the question and the options:\\...  \n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_data = first_per_title.apply(split_row, axis=1)\n",
    "\n",
    "# Flatten the list of lists into a single list of dictionaries\n",
    "flattened_data = [item for sublist in expanded_data for item in sublist]\n",
    "\n",
    "test_df = pd.DataFrame(flattened_data)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on GPT4o\n",
    "\n",
    "Exploring how changing the chunking of the retriever documents will impact the accuracy of the model results, and finding the optimal \n",
    "\n",
    "- Test 1: Chunk_size = 1000, chunk_overlap = 0\n",
    "- Test 2: Chunk size = 2000, chunk_overlap = 0\n",
    "- Test 3: Chunk size = 2000, chunk_overlap = 100\n",
    "- Test 4: Chunk size = 1000, chunk_overlap = 100\n",
    "\n",
    "Each answer is given a score and then the scores are compared at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector store creation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to allow for creation of vector stores with varying chunk sizes and chunk overlaps\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def create_embeddings_from_pdf(pdf_path, embedding_path, chunk_size, chunk_overlap):\n",
    "    # Read PDF\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    # Clean text\n",
    "    text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # Create text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    # Split text into documents\n",
    "    documents = text_splitter.create_documents([text])\n",
    "    print(f\"Total documents created: {len(documents)}\")\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    # embeddings = AzureOpenAIEmbeddings(\n",
    "    #     azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "    #     api_key=os.environ['AZURE_OPENAI_API_KEY'], \n",
    "    #     model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "    #     azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME']\n",
    "    # )\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    \n",
    "    # Create and save vector store\n",
    "    try:\n",
    "        # Use create_documents method to maintain metadata\n",
    "        docsearch = FAISS.from_documents(documents, embedding=embeddings)\n",
    "        \n",
    "        # Ensure embedding path exists\n",
    "        os.makedirs(embedding_path, exist_ok=True)\n",
    "        \n",
    "        # Save locally\n",
    "        docsearch.save_local(folder_path=embedding_path)\n",
    "        print(f\"Embeddings saved to {embedding_path}\")\n",
    "        \n",
    "        return docsearch\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating embeddings: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the tests...\n",
    "## Test 1\n",
    "Chunk_size = 1000, chunk_overlap = 0\n",
    "\n",
    "Vector store with those specifications are created first, before undergoing inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Enable progress bar for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents created: 1431\n",
      "Embeddings saved to ./embeddings-test1\n",
      "Vector store ./data/(edited) DSA textbook Python.pdf for Test 1 to ./embeddings-test1 is a success!\n"
     ]
    }
   ],
   "source": [
    "# Creating the vector store for Test 1\n",
    "\n",
    "pdf_path = './data/(edited) DSA textbook Python.pdf'\n",
    "embedding_path = './embeddings-test1'\n",
    "vector_store = create_embeddings_from_pdf(pdf_path, embedding_path, 1000, 0)\n",
    "\n",
    "if vector_store != None:\n",
    "    print(f\"Vector store {pdf_path} for Test 1 to {embedding_path} is a success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time evaluation set-up using LangSmith (LLM-as-a-Judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset (without labels/aka. reference/aka. ground truth data)\n",
    "from langsmith import Client\n",
    "\n",
    "# QA\n",
    "inputs = test_df[\"Question\"].tolist()\n",
    "\n",
    "# outputs = \n",
    "# qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "qa_pairs = [{\"question\": q} for q in test_df[\"Question\"]]\n",
    "\n",
    "# Create dataset\n",
    "client = Client()\n",
    "dataset_name = \"Algotutor_MainDataset\"\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Testset for optimising retrievers\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],\n",
    "    #outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG\n",
    "import os\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "class RagBot:\n",
    "    \n",
    "    def __init__(self, retriever, model: str = 'gpt-4o'):\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        # self._client = wrap_openai(AzureOpenAI(\n",
    "        #     azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "        #     api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "        #     api_version=os.environ['AZURE_OPENAI_API_VERSION']\n",
    "        # ))\n",
    "        self._client = wrap_openai(openai.Client())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.similarity_search(question, k=2)\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        similar = self.retrieve_docs(question)\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a teaching assistant. Your task is to answer student query about Data Structures and Algorithms in Python course. If user asks any query beyond data structures and algorithms, tell the user you are not an expert of the topic.\"\n",
    "                    \"Answer the question based only on the following context:\\n\\n\"\n",
    "                    f\"Context:\\n\\n{similar}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        # Evaluators will expect \"answer\" and \"contexts\"\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in similar],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "import textwrap\n",
    "\n",
    "# Checking whether the answer is accurate to the docs retrieved\n",
    "# answer_accuracy_evaluator = LangChainStringEvaluator(\n",
    "#   \"labeled_score_string\",\n",
    "#   config={\n",
    "#       \"criteria\": {\n",
    "#           \"accuracy\": textwrap.dedent(\"\"\"Is the Assistant's Answer grounded in the Ground Truth documentation? A score of [[1]] means that the\n",
    "#             Assistant answer contains is not at all based upon / grounded in the Groun Truth documentation. A score of [[5]] means \n",
    "#             that the Assistant answer contains some information (e.g., a hallucination) that is not captured in the Ground Truth \n",
    "#             documentation. A score of [[10]] means that the Assistant answer is fully based upon the in the Ground Truth documentation.\"\"\"\n",
    "#           )\n",
    "#       },\n",
    "#       # If you want the score to be saved on a scale from 0 to 1\n",
    "#       \"normalize_by\": 10,\n",
    "#   },\n",
    "#   prepare_data=lambda run, example: {\n",
    "#         \"prediction\": run.outputs[\"answer\"],\n",
    "#         \"reference\": run.outputs[\"contexts\"],\n",
    "#         \"input\": example.inputs[\"question\"],\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# Checking whether the retrieved documents are relevant to question\n",
    "docs_relevance_evaluator = LangChainStringEvaluator(\n",
    "    \"score_string\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"document_relevance\": textwrap.dedent(\n",
    "                \"\"\"The response is a set of documents retrieved from a vectorstore. The input is a question\n",
    "            used for retrieval. You will score whether the Assistant's response (retrieved docs) is relevant to the Ground Truth \n",
    "            question. A score of [[1]] means that none of the Assistant's response documents contain information useful in answering or addressing the user's input.\n",
    "            A score of [[5]] means that the Assistant answer contains some relevant documents that can at least partially answer the user's question or input. \n",
    "            A score of [[10]] means that the user input can be fully answered using the content in the first retrieved doc(s).\"\"\"\n",
    "            )\n",
    "        },\n",
    "        # If you want the score to be saved on a scale from 0 to 1\n",
    "        \"normalize_by\": 10\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"contexts\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test 1 using first retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_API_KEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])\n",
    "\n",
    "docsearch = FAISS.load_local(\"./embeddings-test1\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "rag_bot = RagBot(docsearch)\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Use this for evaluation of retrieved documents and hallucinations\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/algotutor-fyp/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-1-1aab139f' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=853581aa-555e-4eca-a322-25194d6372e3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set1 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-2-ee11b364' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=c27acea5-7f7e-40c8-8ec4-4a5abca8556f\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:44,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set2 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-3-b3775221' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=321c6129-9235-40f3-92d6-76db5bcd65a7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:20,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set3 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-4-154aa696' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=da78d194-6629-498f-8a0e-ae175de3d451\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:16,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set4 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-5-f265f1b9' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=8ad6dac5-612a-4489-a0ae-869e0b6abc9c\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:18,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set5 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-6-1b2e4b31' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=559a792a-0872-428e-84ff-2f913192971c\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:21,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set6 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-7-b582aef2' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=feff2324-e68a-4759-a144-2554d03aff14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set7 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-8-7d496f3f' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=aba28f6b-76ee-4e0e-a85a-20e3c849ac52\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:16,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set8 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-9-ef53b19a' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=fe57c17a-961f-47a9-85d1-07dff0d6cc5b\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:16,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set9 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap0-doc-relevance-10-0aad8cb5' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/26ec1cbb-8079-4a3a-bd80-1141f080e39f/compare?selectedSessions=b03f93b9-73c9-49bc-bead-60e816c537b2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:12,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set10 evaluation completed\n"
     ]
    }
   ],
   "source": [
    "# Dataset has been split on LangSmith interface into 10 splits\n",
    "# This is to bypass the token restriction on the OpenAI API calls\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "for setnumber in range(1, 11):\n",
    "    dataset_name = \"Algotutor_MainDataset\"\n",
    "    experiment_results = evaluate(\n",
    "        predict_rag_answer_with_context,\n",
    "        data=client.list_examples(dataset_name=dataset_name, splits=[f\"set{setnumber}\"]),\n",
    "        evaluators=[docs_relevance_evaluator],\n",
    "        experiment_prefix=f\"rag-chunk1000-overlap0-doc-relevance-{setnumber}\",\n",
    "        # Any experiment metadata can be specified here\n",
    "        metadata={\n",
    "            \"variant\": \"chunk_size=1000, chunk_overlap=0\",\n",
    "        },\n",
    "    )\n",
    "    print(f\"Datasplit set{setnumber} evaluation completed\")\n",
    "\n",
    "    # Sleep in order to bypass the minute rate limit on the token calls\n",
    "    if setnumber < 10:\n",
    "        sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
      "/tmp/ipykernel_678/4090098211.py:5: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>outputs.contexts</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>error</th>\n",
       "      <th>id</th>\n",
       "      <th>feedback.score_string:document_relevance</th>\n",
       "      <th>input.example.question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your answer is incorrect. Your understanding o...</td>\n",
       "      <td>[page_content='configuration of the Queue Visu...</td>\n",
       "      <td>4.325442</td>\n",
       "      <td>None</td>\n",
       "      <td>25e8b861-0d1f-40d8-8e68-b69fb89ae9ba</td>\n",
       "      <td>0.5</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your answer is correct. Your understanding is ...</td>\n",
       "      <td>[page_content='configuration of the Queue Visu...</td>\n",
       "      <td>3.903861</td>\n",
       "      <td>None</td>\n",
       "      <td>2c6860b7-53cb-47df-9a33-975acf198691</td>\n",
       "      <td>0.5</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your answer is correct. Your understanding is ...</td>\n",
       "      <td>[page_content='you can see, the time required ...</td>\n",
       "      <td>4.223810</td>\n",
       "      <td>None</td>\n",
       "      <td>ec0b6271-e169-4056-b798-f79e8b49ebf7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your answer is correct. Your understanding is ...</td>\n",
       "      <td>[page_content='trickiest parts isremembering w...</td>\n",
       "      <td>3.491941</td>\n",
       "      <td>None</td>\n",
       "      <td>b5f5fda2-49fd-4d24-90af-05a951f43166</td>\n",
       "      <td>0.5</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your answer is wrong. Your understanding is co...</td>\n",
       "      <td>[page_content='configuration of the Queue Visu...</td>\n",
       "      <td>5.009560</td>\n",
       "      <td>None</td>\n",
       "      <td>9f8e1409-e856-4195-b487-f8d922819f4d</td>\n",
       "      <td>0.5</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      outputs.answer  \\\n",
       "0  Your answer is incorrect. Your understanding o...   \n",
       "1  Your answer is correct. Your understanding is ...   \n",
       "2  Your answer is correct. Your understanding is ...   \n",
       "3  Your answer is correct. Your understanding is ...   \n",
       "4  Your answer is wrong. Your understanding is co...   \n",
       "\n",
       "                                    outputs.contexts  execution_time error  \\\n",
       "0  [page_content='configuration of the Queue Visu...        4.325442  None   \n",
       "1  [page_content='configuration of the Queue Visu...        3.903861  None   \n",
       "2  [page_content='you can see, the time required ...        4.223810  None   \n",
       "3  [page_content='trickiest parts isremembering w...        3.491941  None   \n",
       "4  [page_content='configuration of the Queue Visu...        5.009560  None   \n",
       "\n",
       "                                     id  \\\n",
       "0  25e8b861-0d1f-40d8-8e68-b69fb89ae9ba   \n",
       "1  2c6860b7-53cb-47df-9a33-975acf198691   \n",
       "2  ec0b6271-e169-4056-b798-f79e8b49ebf7   \n",
       "3  b5f5fda2-49fd-4d24-90af-05a951f43166   \n",
       "4  9f8e1409-e856-4195-b487-f8d922819f4d   \n",
       "\n",
       "   feedback.score_string:document_relevance  \\\n",
       "0                                       0.5   \n",
       "1                                       0.5   \n",
       "2                                       1.0   \n",
       "3                                       0.5   \n",
       "4                                       0.5   \n",
       "\n",
       "                              input.example.question  \n",
       "0  \\n        Given the question and the options:\\...  \n",
       "1  \\n        Given the question and the options:\\...  \n",
       "2  \\n        Given the question and the options:\\...  \n",
       "3  \\n        Given the question and the options:\\...  \n",
       "4  \\n        Given the question and the options:\\...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_names = ['rag-chunk1000-overlap0-doc-relevance-1-1aab139f', 'rag-chunk1000-overlap0-doc-relevance-2-ee11b364', 'rag-chunk1000-overlap0-doc-relevance-3-b3775221', 'rag-chunk1000-overlap0-doc-relevance-4-154aa696', 'rag-chunk1000-overlap0-doc-relevance-5-f265f1b9', 'rag-chunk1000-overlap0-doc-relevance-6-1b2e4b31', 'rag-chunk1000-overlap0-doc-relevance-7-b582aef2', 'rag-chunk1000-overlap0-doc-relevance-8-7d496f3f', 'rag-chunk1000-overlap0-doc-relevance-9-ef53b19a', 'rag-chunk1000-overlap0-doc-relevance-10-0aad8cb5']\n",
    "\n",
    "#for projectidx in range(len(project_names)):\n",
    "\n",
    "all_dfs = [client.get_test_results(project_name=project_names[projectidx]) for projectidx in range(len(project_names))]\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   outputs.answer                            96 non-null     object \n",
      " 1   outputs.contexts                          96 non-null     object \n",
      " 2   execution_time                            96 non-null     float64\n",
      " 3   error                                     0 non-null      object \n",
      " 4   id                                        96 non-null     object \n",
      " 5   feedback.score_string:document_relevance  96 non-null     float64\n",
      " 6   input.example.question                    96 non-null     object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 5.4+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_678/3690702879.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df.rename(columns=new_column_names, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Merge the two DataFrames on the matching columns\n",
    "merge_df = pd.merge(\n",
    "    combined_df, test_df,\n",
    "    left_on=\"input.example.question\",\n",
    "    right_on=\"Question\",\n",
    "    how=\"inner\"  # Use \"inner\" to include only matching rows\n",
    ")\n",
    "\n",
    "desired_column_order = [\n",
    "    \"id\",\n",
    "    \"Title\",\n",
    "    \"input.example.question\",\n",
    "    \"outputs.answer\",\n",
    "    \"outputs.contexts\",\n",
    "    \"feedback.score_string:document_relevance\",\n",
    "    \"execution_time\",\n",
    "    \"error\"\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "results_df = merge_df[desired_column_order]\n",
    "\n",
    "new_column_names = {\n",
    "    \"id\": \"ID\",\n",
    "    \"Title\": \"Title\",\n",
    "    \"input.example.question\": \"Question\",  \n",
    "    \"outputs.answer\": \"Model Answer\",                  \n",
    "    \"outputs.contexts\": \"Retrieved Context\",\n",
    "    \"feedback.score_string:document_relevance\": \"Relevance Score\",\n",
    "    \"execution_time\": \"Execution Time\",\n",
    "    \"error\": \"Error\"\n",
    "}\n",
    "\n",
    "results_df.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Question</th>\n",
       "      <th>Model Answer</th>\n",
       "      <th>Retrieved Context</th>\n",
       "      <th>Relevance Score</th>\n",
       "      <th>Execution Time</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25e8b861-0d1f-40d8-8e68-b69fb89ae9ba</td>\n",
       "      <td>Medium Stacks and Queues</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "      <td>Your answer is incorrect. Your understanding o...</td>\n",
       "      <td>[page_content='configuration of the Queue Visu...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.325442</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c6860b7-53cb-47df-9a33-975acf198691</td>\n",
       "      <td>Medium Stacks and Queues</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "      <td>Your answer is correct. Your understanding is ...</td>\n",
       "      <td>[page_content='configuration of the Queue Visu...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.903861</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ec0b6271-e169-4056-b798-f79e8b49ebf7</td>\n",
       "      <td>Medium Trees</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "      <td>Your answer is correct. Your understanding is ...</td>\n",
       "      <td>[page_content='you can see, the time required ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.223810</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5f5fda2-49fd-4d24-90af-05a951f43166</td>\n",
       "      <td>Medium Recursion</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "      <td>Your answer is correct. Your understanding is ...</td>\n",
       "      <td>[page_content='trickiest parts isremembering w...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.491941</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9f8e1409-e856-4195-b487-f8d922819f4d</td>\n",
       "      <td>Medium Stacks and Queues</td>\n",
       "      <td>\\n        Given the question and the options:\\...</td>\n",
       "      <td>Your answer is wrong. Your understanding is co...</td>\n",
       "      <td>[page_content='configuration of the Queue Visu...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.009560</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID                     Title  \\\n",
       "0  25e8b861-0d1f-40d8-8e68-b69fb89ae9ba  Medium Stacks and Queues   \n",
       "1  2c6860b7-53cb-47df-9a33-975acf198691  Medium Stacks and Queues   \n",
       "2  ec0b6271-e169-4056-b798-f79e8b49ebf7              Medium Trees   \n",
       "3  b5f5fda2-49fd-4d24-90af-05a951f43166          Medium Recursion   \n",
       "4  9f8e1409-e856-4195-b487-f8d922819f4d  Medium Stacks and Queues   \n",
       "\n",
       "                                            Question  \\\n",
       "0  \\n        Given the question and the options:\\...   \n",
       "1  \\n        Given the question and the options:\\...   \n",
       "2  \\n        Given the question and the options:\\...   \n",
       "3  \\n        Given the question and the options:\\...   \n",
       "4  \\n        Given the question and the options:\\...   \n",
       "\n",
       "                                        Model Answer  \\\n",
       "0  Your answer is incorrect. Your understanding o...   \n",
       "1  Your answer is correct. Your understanding is ...   \n",
       "2  Your answer is correct. Your understanding is ...   \n",
       "3  Your answer is correct. Your understanding is ...   \n",
       "4  Your answer is wrong. Your understanding is co...   \n",
       "\n",
       "                                   Retrieved Context  Relevance Score  \\\n",
       "0  [page_content='configuration of the Queue Visu...              0.5   \n",
       "1  [page_content='configuration of the Queue Visu...              0.5   \n",
       "2  [page_content='you can see, the time required ...              1.0   \n",
       "3  [page_content='trickiest parts isremembering w...              0.5   \n",
       "4  [page_content='configuration of the Queue Visu...              0.5   \n",
       "\n",
       "   Execution Time Error  \n",
       "0        4.325442  None  \n",
       "1        3.903861  None  \n",
       "2        4.223810  None  \n",
       "3        3.491941  None  \n",
       "4        5.009560  None  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ID                 96 non-null     object \n",
      " 1   Title              96 non-null     object \n",
      " 2   Question           96 non-null     object \n",
      " 3   Model Answer       96 non-null     object \n",
      " 4   Retrieved Context  96 non-null     object \n",
      " 5   Relevance Score    96 non-null     float64\n",
      " 6   Execution Time     96 non-null     float64\n",
      " 7   Error              0 non-null      object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 6.1+ KB\n"
     ]
    }
   ],
   "source": [
    "results_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for Test 1\n",
    "\n",
    "Calculating the score by taking the mean of all the relevance scores for each question/retrieved context pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Test 1 retriever: 0.7145833333333332\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score for Test 1 retriever: {results_df['Relevance Score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2\n",
    "Chunk_size = 2000, chunk_overlap = 0\n",
    "\n",
    "Vector store with those specifications are created first, before undergoing inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents created: 715\n",
      "Embeddings saved to ./embeddings-test2\n",
      "Vector store ./data/(edited) DSA textbook Python.pdf for Test 2 to ./embeddings-test2 is a success!\n"
     ]
    }
   ],
   "source": [
    "# Creating the vector store for Test 1\n",
    "\n",
    "pdf_path = './data/(edited) DSA textbook Python.pdf'\n",
    "embedding_path = './embeddings-test2'\n",
    "vector_store = create_embeddings_from_pdf(pdf_path, embedding_path, 2000, 0)\n",
    "\n",
    "if vector_store != None:\n",
    "    print(f\"Vector store {pdf_path} for Test 2 to {embedding_path} is a success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test 2 using second retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_API_KEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])\n",
    "\n",
    "docsearch = FAISS.load_local(\"./embeddings-test2\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "rag_bot = RagBot(docsearch)\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Use this for evaluation of retrieved documents and hallucinations\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-1-f68e44f4' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=c67bb198-6bc0-45b2-b254-7a3a559fd558\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set1 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-2-8c3ce496' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=14aca239-b155-4c9c-9a37-e213553a5866\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set2 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-3-ef140a31' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=09cff7d1-20bb-4bcd-95b9-f49211700f73\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set3 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-4-ae6d3aee' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=f8ad8abd-9806-481f-908b-d89a267728cd\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set4 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-5-4560bbce' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=19732a25-0e0a-460b-a8f3-a83089ebd9a8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set5 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-6-57993c74' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=5a8207a6-dcb8-4cbf-a78e-a19b5c49adaf\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set6 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-7-10cae52f' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=132a80ac-1f95-46ea-a47d-0245da4dd967\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set7 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-8-e46801b5' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=457109ac-bcab-451f-8b67-6cc68785d295\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set8 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-9-02eef999' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=c38b9ce6-a2ef-41e0-a4a4-75ad6f1889f3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set9 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-10-15e48fb8' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=253a5448-6f4c-47e9-9573-e3c4d7fbd32f\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:13,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set10 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-11-9b60f173' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=c8d65dc6-e163-4c2a-b575-b6530fc71042\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set11 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-12-d20e1afa' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=3348c757-aca3-450e-80a3-1af263d86713\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set12 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-13-af0a3865' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=68de185d-1a12-4822-b48c-94a525fdab26\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set13 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-14-5f083228' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=1cf4530a-5af1-4350-b9c3-37bd9c8ee401\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set14 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-15-74f68302' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=27e87d38-25ec-43ae-b9bc-8954fe174674\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set15 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-16-c09df657' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=d5a8cc8b-5586-4c56-b815-b4b7ffe94603\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set16 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-17-0ccdea9e' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=5fc9b7e2-ab61-4397-b875-9fdfbdf24ba7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set17 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-18-af9cb8ce' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=3d2a98e4-3479-4477-a07d-f57900abc431\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set18 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-19-43de23fd' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=fff93734-4565-4eab-9d32-06e9af003f59\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set19 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap0-doc-relevance-20-05145500' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=f7242759-6acc-4ee6-8bf1-b9f1d72041ec\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:11,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set20 evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset has been split on LangSmith interface into 20 splits\n",
    "# This is to bypass the token restriction on the OpenAI API calls\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "for setnumber in range(1, 21):\n",
    "    dataset_name = \"Algotutor_Dataset_20split\"\n",
    "    experiment_results = evaluate(\n",
    "        predict_rag_answer_with_context,\n",
    "        data=client.list_examples(dataset_name=dataset_name, splits=[f\"set{setnumber}\"]),\n",
    "        evaluators=[docs_relevance_evaluator],\n",
    "        experiment_prefix=f\"rag-chunk2000-overlap0-doc-relevance-{setnumber}\",\n",
    "        # Any experiment metadata can be specified here\n",
    "        metadata={\n",
    "            \"variant\": \"chunk_size=2000, chunk_overlap=0\",\n",
    "        },\n",
    "    )\n",
    "    print(f\"Datasplit set{setnumber} evaluation completed\")\n",
    "\n",
    "    # Sleep in order to bypass the minute rate limit on the token calls\n",
    "    if setnumber < 20:\n",
    "        sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
      "/tmp/ipykernel_678/690879135.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Test 2 retriever: 0.671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_678/690879135.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df_test2.rename(columns=new_column_names, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "project_names_test2 = ['rag-chunk2000-overlap0-doc-relevance-1-f68e44f4', 'rag-chunk2000-overlap0-doc-relevance-2-8c3ce496', 'rag-chunk2000-overlap0-doc-relevance-3-ef140a31', 'rag-chunk2000-overlap0-doc-relevance-4-ae6d3aee', 'rag-chunk2000-overlap0-doc-relevance-5-4560bbce', 'rag-chunk2000-overlap0-doc-relevance-6-57993c74', 'rag-chunk2000-overlap0-doc-relevance-7-10cae52f', 'rag-chunk2000-overlap0-doc-relevance-8-e46801b5', 'rag-chunk2000-overlap0-doc-relevance-9-02eef999', 'rag-chunk2000-overlap0-doc-relevance-10-15e48fb8', 'rag-chunk2000-overlap0-doc-relevance-11-9b60f173', 'rag-chunk2000-overlap0-doc-relevance-12-d20e1afa', 'rag-chunk2000-overlap0-doc-relevance-13-af0a3865', 'rag-chunk2000-overlap0-doc-relevance-14-5f083228', 'rag-chunk2000-overlap0-doc-relevance-15-74f68302', 'rag-chunk2000-overlap0-doc-relevance-16-c09df657','rag-chunk2000-overlap0-doc-relevance-17-0ccdea9e', 'rag-chunk2000-overlap0-doc-relevance-18-af9cb8ce', 'rag-chunk2000-overlap0-doc-relevance-19-43de23fd', 'rag-chunk2000-overlap0-doc-relevance-20-05145500']\n",
    "\n",
    "all_dfs_test2 = [client.get_test_results(project_name=project_names_test2[projectidx]) for projectidx in range(len(project_names_test2))]\n",
    "combined_df_test2 = pd.concat(all_dfs_test2, ignore_index=True)\n",
    "\n",
    "# Merge the two DataFrames on the matching columns\n",
    "merge_df_test2 = pd.merge(\n",
    "    combined_df_test2, test_df,\n",
    "    left_on=\"input.example.question\",\n",
    "    right_on=\"Question\",\n",
    "    how=\"inner\"  # Use \"inner\" to include only matching rows\n",
    ")\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "results_df_test2 = merge_df_test2[desired_column_order]\n",
    "\n",
    "results_df_test2.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Test 2 retriever: 0.671875\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score for Test 2 retriever: {results_df_test2['Relevance Score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3\n",
    "Chunk_size = 2000, chunk_overlap = 100\n",
    "\n",
    "Vector store with those specifications are created first, before undergoing inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents created: 751\n",
      "Embeddings saved to ./embeddings-test3\n",
      "Vector store ./data/(edited) DSA textbook Python.pdf for Test 3 to ./embeddings-test3 is a success!\n"
     ]
    }
   ],
   "source": [
    "# Creating the vector store for Test 1\n",
    "\n",
    "pdf_path = './data/(edited) DSA textbook Python.pdf'\n",
    "embedding_path = './embeddings-test3'\n",
    "vector_store = create_embeddings_from_pdf(pdf_path, embedding_path, 2000, 100)\n",
    "\n",
    "if vector_store != None:\n",
    "    print(f\"Vector store {pdf_path} for Test 3 to {embedding_path} is a success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test 3 using third retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_API_KEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])\n",
    "\n",
    "docsearch = FAISS.load_local(\"./embeddings-test3\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "rag_bot = RagBot(docsearch)\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Use this for evaluation of retrieved documents and hallucinations\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-1-db735c22' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=ea4af3ec-de2c-4f8a-8cf2-de5ede7ca681\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set1 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-2-e33de573' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=41d07cba-fd39-483c-8ad7-ffa2cd58fae0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set2 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-3-777f0047' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=1800b542-3590-4d6e-a7cd-ff81ffe2728d\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set3 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-4-2cf804c5' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=7d308d5d-efe4-4a12-a810-256994367cb1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set4 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-5-63f09e84' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=f93dcc50-f601-4845-9e13-76aa20304983\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set5 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-6-b79c1e51' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=a135dc34-de08-4ce8-9904-a342d3356a0a\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set6 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-7-9163e970' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=5e41088c-9f09-49d4-a46c-7d6dde0f3fdb\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set7 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-8-958562b8' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=1ffd705b-52df-4836-9de3-a6dc8a2c8711\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set8 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-9-4091d4a2' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=05727576-4133-4390-91ff-3d078ab115cf\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set9 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-10-232412a1' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=762ee04c-c11c-4a9f-889e-2e4d36c7763d\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:15,  5.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set10 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-11-cdf454c6' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=5f255ada-12a5-4f7c-a0de-7d8020cc53f1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set11 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-12-fa301475' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=8858b5b9-3ae8-4e87-bc51-403e2e4e323f\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set12 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-13-217659a1' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=439da68b-2710-40db-9bdb-dbeb823166e9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set13 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-14-7781698d' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=e3bdb1af-13b7-4b1f-97a6-f7516faa3e5f\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:11,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set14 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-15-df4d8554' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=828193f2-b409-445f-807d-9d3740051ce1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set15 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-16-627ac9e4' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=1494c849-bf3b-478c-abbf-3699473990b3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set16 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-17-9cdaf4a1' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=033f9461-d617-471b-9700-65aaa60a5ff2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set17 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-18-c717e573' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=c07407ee-ebf6-4e82-be4d-e187f126f817\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set18 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-19-7c6a558a' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=cf170818-8bff-480f-b1a8-a00f834d8ee2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set19 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk2000-overlap100-doc-relevance-20-94845d60' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=5527c247-30dd-4a07-bd41-27ee14cb0405\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:11,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set20 evaluation completed\n"
     ]
    }
   ],
   "source": [
    "# Dataset has been split on LangSmith interface into 20 splits\n",
    "# This is to bypass the token restriction on the OpenAI API calls\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "for setnumber in range(1, 21):\n",
    "    dataset_name = \"Algotutor_Dataset_20split\"\n",
    "    experiment_results = evaluate(\n",
    "        predict_rag_answer_with_context,\n",
    "        data=client.list_examples(dataset_name=dataset_name, splits=[f\"set{setnumber}\"]),\n",
    "        evaluators=[docs_relevance_evaluator],\n",
    "        experiment_prefix=f\"rag-chunk2000-overlap100-doc-relevance-{setnumber}\",\n",
    "        # Any experiment metadata can be specified here\n",
    "        metadata={\n",
    "            \"variant\": \"chunk_size=2000, chunk_overlap=100\",\n",
    "        },\n",
    "    )\n",
    "    print(f\"Datasplit set{setnumber} evaluation completed\")\n",
    "\n",
    "    # Sleep in order to bypass the minute rate limit on the token calls\n",
    "    if setnumber < 20:\n",
    "        sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
      "/tmp/ipykernel_678/92923380.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df_test3.rename(columns=new_column_names, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "project_names_test3= ['rag-chunk2000-overlap100-doc-relevance-1-db735c22', 'rag-chunk2000-overlap100-doc-relevance-2-e33de573', 'rag-chunk2000-overlap100-doc-relevance-3-777f0047', 'rag-chunk2000-overlap100-doc-relevance-4-2cf804c5', 'rag-chunk2000-overlap100-doc-relevance-5-63f09e84', 'rag-chunk2000-overlap100-doc-relevance-6-b79c1e51', 'rag-chunk2000-overlap100-doc-relevance-7-9163e970', 'rag-chunk2000-overlap100-doc-relevance-8-958562b8', 'rag-chunk2000-overlap100-doc-relevance-9-4091d4a2', 'rag-chunk2000-overlap100-doc-relevance-10-232412a1', 'rag-chunk2000-overlap100-doc-relevance-11-cdf454c6', 'rag-chunk2000-overlap100-doc-relevance-12-fa301475', 'rag-chunk2000-overlap100-doc-relevance-13-217659a1', 'rag-chunk2000-overlap100-doc-relevance-14-7781698d', 'rag-chunk2000-overlap100-doc-relevance-15-df4d8554', 'rag-chunk2000-overlap100-doc-relevance-16-627ac9e4', 'rag-chunk2000-overlap100-doc-relevance-17-9cdaf4a1', 'rag-chunk2000-overlap100-doc-relevance-18-c717e573', 'rag-chunk2000-overlap100-doc-relevance-19-7c6a558a', 'rag-chunk2000-overlap100-doc-relevance-20-94845d60']\n",
    "\n",
    "all_dfs_test3 = [client.get_test_results(project_name=project_names_test3[projectidx]) for projectidx in range(len(project_names_test3))]\n",
    "combined_df_test3 = pd.concat(all_dfs_test3, ignore_index=True)\n",
    "\n",
    "# Merge the two DataFrames on the matching columns\n",
    "merge_df_test3 = pd.merge(\n",
    "    combined_df_test3, test_df,\n",
    "    left_on=\"input.example.question\",\n",
    "    right_on=\"Question\",\n",
    "    how=\"inner\"  # Use \"inner\" to include only matching rows\n",
    ")\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "results_df_test3 = merge_df_test3[desired_column_order]\n",
    "\n",
    "results_df_test3.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Test 3 retriever: 0.6479166666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score for Test 3 retriever: {results_df_test3['Relevance Score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4\n",
    "Chunk_size = 1000, chunk_overlap = 100\n",
    "\n",
    "Vector store with those specifications are created first, before undergoing inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents created: 1585\n",
      "Embeddings saved to ./embeddings-test4\n",
      "Vector store ./data/(edited) DSA textbook Python.pdf for Test 4 to ./embeddings-test4 is a success!\n"
     ]
    }
   ],
   "source": [
    "# Creating the vector store for Test 1\n",
    "\n",
    "pdf_path = './data/(edited) DSA textbook Python.pdf'\n",
    "embedding_path = './embeddings-test4'\n",
    "vector_store = create_embeddings_from_pdf(pdf_path, embedding_path, 1000, 100)\n",
    "\n",
    "if vector_store != None:\n",
    "    print(f\"Vector store {pdf_path} for Test 4 to {embedding_path} is a success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test 4 using fourth retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'], \n",
    "                                   api_key=os.environ['AZURE_OPENAI_API_KEY'], \n",
    "                                   model=os.environ['TEXT_EMBEDDING_MODEL_NAME'],\n",
    "                                   azure_deployment=os.environ['TEXT_EMBEDDING_DEPLOYMENT_NAME'])\n",
    "\n",
    "docsearch = FAISS.load_local(\"./embeddings-test4\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "rag_bot = RagBot(docsearch)\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Use this for evaluation of retrieved documents and hallucinations\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-1-39242bf8' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=5b070019-0bde-48cc-a008-3d2f72641467\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set1 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-2-ffdc9b39' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=4946b109-a453-48e1-8c26-c9bc8369c59b\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set2 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-3-2029bff0' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=4c8e8c2c-d9f3-470a-858f-b19c4940e1f1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:39,  7.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set3 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-4-5028a9fa' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=e41c242f-4a58-4b7f-8ace-3f4b7d3123de\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set4 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-5-f19d72c9' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=4e6c2aab-7235-432a-8e05-50a701587e6e\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set5 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-6-fb109294' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=b99288c1-403d-4841-9ee6-37404e1c018d\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set6 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-7-a0350f08' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=65242bd5-5e7f-4d8e-9fc6-da007563b2cc\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set7 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-8-dadf82ec' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=56a4184b-52b2-40f2-ba80-5ec487c6d3b2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set8 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-9-866a1bd6' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=6d170513-065a-4c3c-8226-ccb1ab5a0143\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set9 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-10-a9cf247d' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=a747f15e-487d-4c01-be86-5bf3486b7e7c\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:15,  5.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set10 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-11-39fb5df0' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=6bc4e71d-e29e-46ce-86e7-b4e77c522fd0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set11 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-12-f82155a2' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=370b463b-1cb7-4023-ad40-3af64d680872\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:17,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set12 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-13-838b4ef8' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=53d54cd1-9466-4ccd-b478-274e98a27b7c\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:14,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set13 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-14-2ec3c3c0' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=4ea3a5a0-33bb-40b9-935a-633adea81496\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set14 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-15-28119639' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=2978c026-550f-4f32-8eb2-1f4e4b5acf87\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:15,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set15 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-16-dc20cbe5' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=a5ff52ff-e600-43cc-903e-1823fc52809c\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set16 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-17-f0ff6a90' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=aba3c07b-13fa-4a63-b735-d8792af699c5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set17 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-18-08aaafb9' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=0af3d50f-21fd-48cc-a164-9dc12b207fd6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set18 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-19-202cd5df' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=33bb1b67-3b2b-4477-b29e-985b25f5788d\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set19 evaluation completed\n",
      "View the evaluation results for experiment: 'rag-chunk1000-overlap100-doc-relevance-20-2c5009fe' at:\n",
      "https://smith.langchain.com/o/65a167b9-d4dd-594a-9fef-747869e69109/datasets/2ffa90d0-c4c7-4365-b7f2-db681b2d2c8a/compare?selectedSessions=38bdda40-c87d-4c55-8a2a-492484e195b0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:12,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasplit set20 evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset has been split on LangSmith interface into 20 splits\n",
    "# This is to bypass the token restriction on the OpenAI API calls\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "for setnumber in range(1, 21):\n",
    "    dataset_name = \"Algotutor_Dataset_20split\"\n",
    "    experiment_results = evaluate(\n",
    "        predict_rag_answer_with_context,\n",
    "        data=client.list_examples(dataset_name=dataset_name, splits=[f\"set{setnumber}\"]),\n",
    "        evaluators=[docs_relevance_evaluator],\n",
    "        experiment_prefix=f\"rag-chunk1000-overlap100-doc-relevance-{setnumber}\",\n",
    "        # Any experiment metadata can be specified here\n",
    "        metadata={\n",
    "            \"variant\": \"chunk_size=1000, chunk_overlap=100\",\n",
    "        },\n",
    "    )\n",
    "    print(f\"Datasplit set{setnumber} evaluation completed\")\n",
    "\n",
    "    # Sleep in order to bypass the minute rate limit on the token calls\n",
    "    if setnumber < 20:\n",
    "        sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:3: UserWarning: Function get_test_results is in beta.\n",
      "  all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
      "/tmp/ipykernel_678/4238294787.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df_test4.rename(columns=new_column_names, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "project_names_test4= ['rag-chunk1000-overlap100-doc-relevance-1-39242bf8', 'rag-chunk1000-overlap100-doc-relevance-2-ffdc9b39', 'rag-chunk1000-overlap100-doc-relevance-3-2029bff0', 'rag-chunk1000-overlap100-doc-relevance-4-5028a9fa', 'rag-chunk1000-overlap100-doc-relevance-5-f19d72c9', 'rag-chunk1000-overlap100-doc-relevance-6-fb109294', 'rag-chunk1000-overlap100-doc-relevance-7-a0350f08', 'rag-chunk1000-overlap100-doc-relevance-8-dadf82ec', 'rag-chunk1000-overlap100-doc-relevance-9-866a1bd6', 'rag-chunk1000-overlap100-doc-relevance-10-a9cf247d', 'rag-chunk1000-overlap100-doc-relevance-11-39fb5df0', 'rag-chunk1000-overlap100-doc-relevance-12-f82155a2', 'rag-chunk1000-overlap100-doc-relevance-13-838b4ef8', 'rag-chunk1000-overlap100-doc-relevance-14-2ec3c3c0', 'rag-chunk1000-overlap100-doc-relevance-15-28119639', 'rag-chunk1000-overlap100-doc-relevance-16-dc20cbe5', 'rag-chunk1000-overlap100-doc-relevance-17-f0ff6a90', 'rag-chunk1000-overlap100-doc-relevance-18-08aaafb9', 'rag-chunk1000-overlap100-doc-relevance-19-202cd5df', 'rag-chunk1000-overlap100-doc-relevance-20-2c5009fe']\n",
    "\n",
    "all_dfs_test4 = [client.get_test_results(project_name=project_names_test4[projectidx]) for projectidx in range(len(project_names_test4))]\n",
    "combined_df_test4 = pd.concat(all_dfs_test4, ignore_index=True)\n",
    "\n",
    "# Merge the two DataFrames on the matching columns\n",
    "merge_df_test4 = pd.merge(\n",
    "    combined_df_test4, test_df,\n",
    "    left_on=\"input.example.question\",\n",
    "    right_on=\"Question\",\n",
    "    how=\"inner\"  # Use \"inner\" to include only matching rows\n",
    ")\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "results_df_test4 = merge_df_test4[desired_column_order]\n",
    "\n",
    "results_df_test4.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Test 4 retriever: 0.7177083333333334\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score for Test 4 retriever: {results_df_test4['Relevance Score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Recap on the retriever's specifications for each test:\n",
    "- Test 1: Chunk_size = 1000, chunk_overlap = 0\n",
    "- Test 2: Chunk size = 2000, chunk_overlap = 0\n",
    "- Test 3: Chunk size = 2000, chunk_overlap = 100\n",
    "- Test 4: Chunk size = 1000, chunk_overlap = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Table Summary of all the retriever's relevance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Score</th>\n",
       "      <th>Chunk_Size</th>\n",
       "      <th>Chunk_Overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.647917</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.717708</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Test     Score  Chunk_Size  Chunk_Overlap\n",
       "0     1  0.714583        1000              0\n",
       "1     2  0.671875        2000              0\n",
       "2     3  0.647917        2000            100\n",
       "3     4  0.717708        1000            100"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [\n",
    "    results_df['Relevance Score'].mean(),\n",
    "    results_df_test2['Relevance Score'].mean(),\n",
    "    results_df_test3['Relevance Score'].mean(),\n",
    "    results_df_test4['Relevance Score'].mean(),\n",
    "]\n",
    "\n",
    "final_df = pd.DataFrame({\n",
    "    'Test': [1, 2, 3, 4],\n",
    "    'Score': scores,\n",
    "    'Chunk_Size': [1000, 2000, 2000, 1000],\n",
    "    'Chunk_Overlap': [0, 0, 100, 100]\n",
    "}, index=None)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the excel file results\n",
    "\n",
    "results_df['Test'] = 1\n",
    "results_df_test2['Test'] = 2\n",
    "results_df_test3['Test'] = 3\n",
    "results_df_test4['Test'] = 4\n",
    "\n",
    "all_results_df = pd.concat([results_df, results_df_test2, results_df_test3, results_df_test4], ignore_index=True)\n",
    "\n",
    "# Saving the concatenated DataFrame to an Excel file\n",
    "all_results_df.to_excel('concatenated_evaluation_results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
